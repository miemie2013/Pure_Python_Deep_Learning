


设bn层的输入X是一个4维张量，形状是(N, C, H, W)，N代表批大小，C代表属性数；
bn层的权重是S，形状是(C, )；bn层的偏移是B，形状是(C, )；
bn层的输出是Y，形状是(N, C, H, W)。那么有

normX = (X-U)/sqrt(V + e)
Y=normX * S + B


由于N、H、W维是无差别地相加的。输入X里有N张图片，每张图片的分辨率是H*W，通道数是C。我们不妨把每一张特征图的每一个像素看作为样本，即我们现在把N个样本分解成了N*H*W个样本，它们有C个属性。
N, C, H, W = X.shape
X = X.transpose(0, 2, 3, 1)   # NHWC格式。我们先把通道放到最后一维，这样reshape时才能精准拿到通道属性。
X = np.reshape(X, (-1, C))    # (M, C)
M = N*H*W   # M是新的批大小

这样，我们就把4维张量X变成了2维张量，形状是(M, C)，其中M = N*H*W。

取特殊值
N=2
C=2
H=2
W=1
e = epsilon
，那么

X = [
[x00, x01],
[x10, x11],
[x20, x21],
[x30, x31]]   # (M, C)

S = [s0, s1]   # (C, )

B = [b0, b1]   # (C, )

Y = [
[y00, y01],
[y10, y11],
[y20, y21],
[y30, y31]]   # (M, C)

grad = [
[dloss/dy00, dloss/dy01],
[dloss/dy10, dloss/dy11],
[dloss/dy20, dloss/dy21],
[dloss/dy30, dloss/dy31]]   # (M, C)

grad是最终loss对本层输出张量Y的梯度，形状和Y一样，是(M, C)。


训练时前向传播有
u0 = (x00 + x10 + x20 + x30) / M   # 不同样本的同一属性（通道）相加
u1 = (x01 + x11 + x21 + x31) / M   # 不同样本的同一属性（通道）相加

v0 = [(x00-u0)^2 + (x10-u0)^2 + (x20-u0)^2 + (x30-u0)^2] / M
同理
v1 = [(x01-u1)^2 + (x11-u1)^2 + (x21-u1)^2 + (x31-u1)^2] / M

即
U = [u0, u1]   # (C, )
S = [v0, v1]   # (C, )


normX = (X-U)/sqrt(V + e)
Y=normX * S + B

下面求梯度：



